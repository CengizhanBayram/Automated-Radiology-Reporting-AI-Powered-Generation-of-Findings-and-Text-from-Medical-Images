{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============== 1) KURULUM ===============\n",
        "!pip install -q medmnist\n",
        "!pip install -q torchvision\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# Drive varsa\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# ==========================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoiv4m677Pb0",
        "outputId": "f23cbaca-a75b-4837-be51-e55fa49fa6df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0wcGKKwy8vW",
        "outputId": "85db7845-c4db-49e5-c9ad-35a5b4572ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 82.8M/82.8M [01:44<00:00, 791kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78468 11219 22433\n"
          ]
        }
      ],
      "source": [
        "# =============== 2) VERİYİ AL ===============\n",
        "from medmnist import INFO, ChestMNIST\n",
        "\n",
        "# ChestMNIST bilgisi\n",
        "info = INFO[\"chestmnist\"]\n",
        "task = info[\"task\"]              # \"multi-label, binary-class\"\n",
        "n_channels = info[\"n_channels\"]  # 1\n",
        "n_classes  = len(info[\"label\"])  # 14\n",
        "\n",
        "# veri setlerini indir\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Lambda(lambda x: x.repeat(3,1,1)),  # 1 kanal → 3 kanal\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = ChestMNIST(split=\"train\", download=True, transform=data_transform, as_rgb=False)\n",
        "val_ds   = ChestMNIST(split=\"val\",   download=True, transform=data_transform, as_rgb=False)\n",
        "test_ds  = ChestMNIST(split=\"test\",  download=True, transform=data_transform, as_rgb=False)\n",
        "\n",
        "print(len(train_ds), len(val_ds), len(test_ds))  # kontrol\n",
        "# ============================================\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== 2) VERİYİ AL ===============\n",
        "from medmnist import INFO, ChestMNIST\n",
        "\n",
        "# ChestMNIST bilgisi\n",
        "info = INFO[\"chestmnist\"]\n",
        "task = info[\"task\"]              # \"multi-label, binary-class\"\n",
        "n_channels = info[\"n_channels\"]  # 1\n",
        "n_classes  = len(info[\"label\"])  # 14\n",
        "\n",
        "# veri setlerini indir\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Lambda(lambda x: x.repeat(3,1,1)),  # 1 kanal → 3 kanal\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = ChestMNIST(split=\"train\", download=True, transform=data_transform, as_rgb=False)\n",
        "val_ds   = ChestMNIST(split=\"val\",   download=True, transform=data_transform, as_rgb=False)\n",
        "test_ds  = ChestMNIST(split=\"test\",  download=True, transform=data_transform, as_rgb=False)\n",
        "\n",
        "print(len(train_ds), len(val_ds), len(test_ds))  # kontrol\n",
        "# ============================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcp1GiKTcQC8",
        "outputId": "ce124a05-a20e-45c6-c59a-c43701223fa5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78468 11219 22433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== 3) DATALOADER ===============\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "# =============================================\n"
      ],
      "metadata": {
        "id": "3WNOZwzAalNz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== 4) MODEL ===============\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "in_feats = model.classifier.in_features\n",
        "model.classifier = nn.Linear(in_feats, n_classes)   # 14 çıkış\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()  # çünkü chestmnist multi-label\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/radiologyst\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "SAVE_PATH = os.path.join(SAVE_DIR, \"chestmnist_best.pt\")\n",
        "# ===========================================\n"
      ],
      "metadata": {
        "id": "MteQG2jK7XSQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== 5) EĞİTİM FONKSİYONLARI ===============\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for imgs, labels in loader:\n",
        "        # medmnist label'ları shape (bs, 14, 1) gelebilir → sıkıştır\n",
        "        labels = labels.squeeze().float()\n",
        "        imgs   = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += loss.item() * imgs.size(0)\n",
        "    return total / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    for imgs, labels in loader:\n",
        "        labels = labels.squeeze().float()\n",
        "        imgs   = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        total += loss.item() * imgs.size(0)\n",
        "    return total / len(loader.dataset)\n",
        "# =========================================================\n"
      ],
      "metadata": {
        "id": "xNCdk5eF7Yk5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== 6) EĞİT ===============\n",
        "MAX_EPOCHS = 15\n",
        "PATIENCE   = 4\n",
        "best_val   = float(\"inf\")\n",
        "no_imp     = 0\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS+1):\n",
        "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss   = evaluate(model, val_loader,   criterion, device)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"[{epoch:02d}/{MAX_EPOCHS}] train={train_loss:.4f}  val={val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val - 1e-4:\n",
        "        best_val = val_loss\n",
        "        no_imp = 0\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"  -> iyileşme var, kaydedildi: {SAVE_PATH}\")\n",
        "    else:\n",
        "        no_imp += 1\n",
        "        print(f\"  -> yok ({no_imp}/{PATIENCE})\")\n",
        "\n",
        "    if no_imp >= PATIENCE:\n",
        "        print(\"early stopping\")\n",
        "        break\n",
        "\n",
        "print(\"bitti. en iyi val:\", best_val)\n",
        "print(\"model:\", SAVE_PATH)\n",
        "# ============================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIBvXaBI7Z2j",
        "outputId": "925db46c-df05-48d7-c2a2-3f6b62d8f486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/15] train=0.1730  val=0.1576\n",
            "  -> iyileşme var, kaydedildi: /content/drive/MyDrive/radiologyst/chestmnist_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== 7) TEST / ÖRNEK TAHMİN ===============\n",
        "@torch.no_grad()\n",
        "def predict_one(model, ds, idx=0):\n",
        "    model.eval()\n",
        "    img, label = ds[idx]\n",
        "    x = img.unsqueeze(0).to(device)\n",
        "    out = model(x)\n",
        "    probs = torch.sigmoid(out).cpu().squeeze(0).tolist()\n",
        "    return probs, label\n",
        "\n",
        "probs, label = predict_one(model, test_ds, idx=0)\n",
        "print(\"ilk test görüntüsü gerçek label:\", label.squeeze().tolist())\n",
        "print(\"model olasılıkları (14 hastalık):\", [round(p,4) for p in probs])\n",
        "# ===========================================\n"
      ],
      "metadata": {
        "id": "B8RNlX3P7bad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# kaç tane örnek kaydedelim?\n",
        "N = 10  # istersen arttır\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/chestmnist_samples\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# ChestMNIST label'ları: 14 boyutlu multi-label vektör\n",
        "# train_ds zaten daha önce oluşturduğumuz dataset\n",
        "for i in range(N):\n",
        "    img, label = train_ds[i]  # img: Tensor (3,224,224), label: (14,)\n",
        "    # tensordan PIL'e çevir\n",
        "    # önce unnormalize edelim:\n",
        "    img_np = img.permute(1, 2, 0).cpu().numpy()\n",
        "    # normalize geri alma (basit, tam değil ama görünmesi için yeter):\n",
        "    img_np = (img_np * 255).clip(0, 255).astype(\"uint8\")\n",
        "    pil = Image.fromarray(img_np)\n",
        "\n",
        "    # label'ı dosya adına da koyabiliriz\n",
        "    # label tensor olabilir, listeye çevir\n",
        "    label_list = label.squeeze().tolist()\n",
        "    # hangi etiketler 1 ise onları yaz\n",
        "    active_idxs = [str(j) for j, v in enumerate(label_list) if v == 1]\n",
        "\n",
        "    fname = f\"sample_{i:02d}_\" + (\"_\".join(active_idxs) if active_idxs else \"none\") + \".png\"\n",
        "    pil.save(os.path.join(out_dir, fname))\n",
        "\n",
        "print(f\"{N} örnek kaydedildi -> {out_dir}\")\n"
      ],
      "metadata": {
        "id": "WP3SGM_17o3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}